#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†å²åŠ¨ä½œå‹ç¼©æœåŠ¡
ç­–ç•¥ï¼šæ€»ç»“å†å²XML + ä¿ç•™æœ€æ–°action + å‹ç¼©æœ€æ–°actionçš„å¤§å­—æ®µ
"""

import json
from typing import List, Dict

try:
    import tiktoken
    HAS_TIKTOKEN = True
except ImportError:
    HAS_TIKTOKEN = False


class ActionCompressor:
    """å†å²åŠ¨ä½œå‹ç¼©å™¨"""
    
    def __init__(self, llm_client):
        """
        åˆå§‹åŒ–
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆç”¨äºæ€»ç»“ï¼‰
        """
        self.llm_client = llm_client
        
        # åˆå§‹åŒ–tiktoken
        if HAS_TIKTOKEN:
            self.encoding = tiktoken.get_encoding("cl100k_base")
        else:
            self.encoding = None
    
    def count_tokens(self, text: str) -> int:
        """ç»Ÿè®¡tokenæ•°"""
        if self.encoding:
            return len(self.encoding.encode(text))
        else:
            chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
            other_chars = len(text) - chinese_chars
            return int(chinese_chars / 1.5 + other_chars / 4)
    
    def compress_if_needed(
        self,
        action_history: List[Dict],
        max_context_window: int,
        save_callback=None  # æ·»åŠ ä¿å­˜å›è°ƒï¼Œç¡®ä¿å‹ç¼©åç«‹å³ä¿å­˜
    ) -> List[Dict]:
        """
        æ£€æŸ¥å¹¶å‹ç¼©å†å²åŠ¨ä½œ
        
        ç­–ç•¥ï¼š
        1. ä¿ç•™æœ€æ–°1æ¡actionï¼ˆå®Œæ•´æˆ–å‹ç¼©å¤§å­—æ®µï¼‰
        2. ä¹‹å‰çš„æ‰€æœ‰actionæ€»ç»“ä¸ºä¸€ä¸ªsummary_action
        
        Args:
            action_history: åŠ¨ä½œå†å²
            max_context_window: æœ€å¤§çª—å£å¤§å°
            
        Returns:
            å‹ç¼©åçš„action_history
        """
        if not action_history:
            return []
        
        # å¦‚æœåªæœ‰ä¸€æ¡
        if len(action_history) == 1:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©å­—æ®µ
            return [self._compress_action_fields(action_history[0], max_context_window // 2)]
        
        # åˆ†ç¦»æœ€æ–°å’Œå†å²
        recent_action = action_history[-1]
        historical_actions = action_history[:-1]
        
        # è®¡ç®—æ•´ä½“tokenæ•°
        total_text = self._actions_to_xml(action_history)
        total_tokens = self.count_tokens(total_text)
        
        # å¦‚æœä¸è¶…é™ï¼Œä¸å‹ç¼©
        if total_tokens <= max_context_window - 20000:
            return action_history
        
        print(f"ğŸ”„ å†å²åŠ¨ä½œéœ€è¦å‹ç¼©: {total_tokens} tokens > {max_context_window - 20000}")
        
        # å‹ç¼©ç­–ç•¥ï¼š
        # 1. å†å² â†’ æ€»ç»“ä¸º5k tokens
        # 2. æœ€æ–° â†’ å‹ç¼©ä¸ºmax_windowçš„50%
        
        summary_action = self._summarize_historical_xml(
            self._actions_to_xml(historical_actions),
            target_tokens=5000  # å†å²æ€»ç»“å›ºå®š5k tokens
        )
        
        # å‹ç¼©æœ€æ–°actionçš„å¤§å­—æ®µï¼ˆ50% of max_windowï¼‰
        compressed_recent = self._compress_action_fields(
            recent_action,
            int(max_context_window * 0.5)  # 80000 * 0.5 = 40000 tokens
        )
        
        result = [summary_action, compressed_recent]
        
        # éªŒè¯å‹ç¼©æ•ˆæœ
        result_xml = self._actions_to_xml(result)
        result_tokens = self.count_tokens(result_xml)
        print(f"âœ… å‹ç¼©å®Œæˆ: {total_tokens} tokens â†’ {result_tokens} tokens (å‹ç¼©æ¯”: {result_tokens/total_tokens*100:.1f}%)")
        
        return result
    
    def _actions_to_xml(self, actions: List[Dict]) -> str:
        """å°†actionsè½¬æ¢ä¸ºXMLæ ¼å¼æ–‡æœ¬"""
        xml_parts = []
        for action in actions:
            tool_name = action.get("tool_name", "")
            arguments = action.get("arguments", {})
            result = action.get("result", {})
            
            action_xml = f"<action>\n  <tool_name>{tool_name}</tool_name>\n"
            
            # å‚æ•°
            for k, v in arguments.items():
                v_str = str(v).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
                action_xml += f"  <tool_use:{k}>{v_str}</tool_use:{k}>\n"
            
            # ç»“æœ
            result_json = json.dumps(result, ensure_ascii=False, indent=2)
            action_xml += f"  <result>\n{result_json}\n  </result>\n</action>"
            
            xml_parts.append(action_xml)
        
        return "\n\n".join(xml_parts)
    
    def _summarize_historical_xml(self, xml_text: str, target_tokens: int = 5000) -> Dict:
        """
        æ€»ç»“å†å²XMLå†…å®¹ä¸ºä¸€ä¸ªsummary action
        
        Args:
            xml_text: å†å²actionsçš„XMLæ–‡æœ¬
            
        Returns:
            ä¸€ä¸ªsummary action
        """
        try:
            from services.llm_client import ChatMessage
            
            prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å†å²åŠ¨ä½œçš„å…³é”®ä¿¡æ¯ï¼ˆä¸¥æ ¼ä¸è¶…è¿‡{target_tokens} tokensï¼‰ï¼š

{xml_text}

è¦æ±‚ï¼š
1. è¯´æ˜æ‰§è¡Œäº†å“ªäº›å·¥å…·
2. å…³é”®çš„è¾“å‡ºå’Œç»“æœ
3. é‡è¦çš„æ–‡ä»¶è·¯å¾„
4. ç›®æ ‡é•¿åº¦ï¼š{target_tokens} tokens
5. æåº¦ç®€æ´ä½†ä¿ç•™æ ¸å¿ƒä¿¡æ¯

è¯·ç”¨ä¸­æ–‡æ€»ç»“ï¼š"""
            
            history = [ChatMessage(role="user", content=prompt)]
            
            response = self.llm_client.chat(
                history=history,
                model=self.llm_client.models[0],
                system_prompt=f"ä½ æ˜¯å†…å®¹æ€»ç»“åŠ©æ‰‹ã€‚ç›®æ ‡ï¼šå°†å†…å®¹å‹ç¼©åˆ°{target_tokens} tokensä»¥å†…ã€‚",
                tool_list=[],
                tool_choice="auto"
            )
            
            summary = response.output if response.status == "success" else "[æ€»ç»“å¤±è´¥]"
            
            return {
                "tool_name": "_historical_summary",
                "arguments": {},
                "result": {
                    "status": "success",
                    "output": summary,
                    "_is_summary": True
                }
            }
        
        except Exception as e:
            print(f"âš ï¸ æ€»ç»“å¤±è´¥: {e}")
            return {
                "tool_name": "_historical_summary",
                "arguments": {},
                "result": {"status": "success", "output": "[å†å²åŠ¨ä½œå·²çœç•¥]", "_is_summary": True}
            }
    
    def _compress_action_fields(self, action: Dict, max_field_tokens: int) -> Dict:
        """
        å‹ç¼©actionä¸­çš„å¤§å­—æ®µï¼ˆargumentså’Œresultï¼‰
        
        Args:
            action: åŸå§‹action
            max_field_tokens: å•ä¸ªå­—æ®µçš„æœ€å¤§tokenæ•°ï¼ˆé€šå¸¸æ˜¯max_context_window/2ï¼‰
            
        Returns:
            å‹ç¼©åçš„action
        """
        compressed_action = action.copy()
        
        # å‹ç¼©argumentsä¸­çš„å¤§å­—æ®µ
        if "arguments" in compressed_action:
            compressed_args = {}
            for k, v in compressed_action["arguments"].items():
                v_str = str(v)
                v_tokens = self.count_tokens(v_str)
                
                if v_tokens > max_field_tokens:
                    print(f"   ğŸ¤– LLMå‹ç¼©arguments.{k}: {v_tokens} tokens â†’ {max_field_tokens} tokens")
                    compressed_v = self._llm_compress_field(v_str, max_field_tokens, action.get("tool_name", "unknown"))
                    compressed_args[k] = compressed_v
                else:
                    compressed_args[k] = v
            compressed_action["arguments"] = compressed_args
        
        # å‹ç¼©result.output
        if "result" in compressed_action and "output" in compressed_action["result"]:
            output = compressed_action["result"]["output"]
            output_tokens = self.count_tokens(output)
            
            if output_tokens > max_field_tokens:
                print(f"   ğŸ¤– LLMå‹ç¼©result.output: {output_tokens} tokens â†’ {max_field_tokens} tokens")
                compressed_output = self._llm_compress_field(output, max_field_tokens, action.get("tool_name", "unknown"))
                compressed_action["result"]["output"] = compressed_output
                compressed_action["result"]["_compressed"] = True
                compressed_action["result"]["_original_tokens"] = output_tokens
        
        return compressed_action
    
    def _llm_compress_field(self, text: str, target_tokens: int, tool_name: str) -> str:
        """
        ä½¿ç”¨LLMæ™ºèƒ½å‹ç¼©å•ä¸ªå­—æ®µ
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            target_tokens: ç›®æ ‡tokenæ•°
            tool_name: å·¥å…·åç§°ï¼ˆç”¨äºä¼˜åŒ–æç¤ºè¯ï¼‰
            
        Returns:
            å‹ç¼©åçš„æ–‡æœ¬
        """
        try:
            from services.llm_client import ChatMessage
            
            # æ ¹æ®å·¥å…·ç±»å‹å®šåˆ¶æç¤ºè¯
            if "parse" in tool_name.lower() or "read" in tool_name.lower():
                content_type = "æ–‡æ¡£å†…å®¹"
                focus = "ä¿ç•™æ–‡æ¡£çš„å…³é”®ç« èŠ‚ã€æ ¸å¿ƒè®ºç‚¹ã€é‡è¦æ•°æ®å’Œç»“è®º"
            elif "execute" in tool_name.lower() or "run" in tool_name.lower():
                content_type = "ä»£ç æ‰§è¡Œç»“æœ"
                focus = "ä¿ç•™å…³é”®è¾“å‡ºã€é”™è¯¯ä¿¡æ¯ã€è¿”å›å€¼å’Œæ‰§è¡ŒçŠ¶æ€"
            elif "search" in tool_name.lower():
                content_type = "æœç´¢ç»“æœ"
                focus = "ä¿ç•™æœ€ç›¸å…³çš„æœç´¢ç»“æœå’Œå…³é”®åŒ¹é…ä¿¡æ¯"
            else:
                content_type = "å†…å®¹"
                focus = "ä¿ç•™æœ€é‡è¦çš„æ ¸å¿ƒä¿¡æ¯"
            
            prompt = f"""è¯·æ™ºèƒ½å‹ç¼©ä»¥ä¸‹{content_type}åˆ°çº¦{target_tokens} tokensï¼š

{text}

å‹ç¼©è¦æ±‚ï¼š
1. ç›®æ ‡é•¿åº¦ï¼š{target_tokens} tokens
2. {focus}
3. ä¿æŒä¿¡æ¯çš„è¿è´¯æ€§å’Œå¯è¯»æ€§
4. ä½¿ç”¨æ€»ç»“å’Œæç‚¼ï¼Œè€Œéç®€å•æˆªæ–­
5. å¦‚æœæœ‰ç»“æ„åŒ–å†…å®¹ï¼ˆè¡¨æ ¼ã€åˆ—è¡¨ï¼‰ï¼Œä¿ç•™å…³é”®éƒ¨åˆ†

è¯·ç›´æ¥è¾“å‡ºå‹ç¼©åçš„å†…å®¹ï¼ˆä¸è¦é¢å¤–è¯´æ˜ï¼‰ï¼š"""
            
            history = [ChatMessage(role="user", content=prompt)]
            
            response = self.llm_client.chat(
                history=history,
                model=self.llm_client.models[0],
                system_prompt=f"ä½ æ˜¯æ™ºèƒ½å†…å®¹å‹ç¼©åŠ©æ‰‹ã€‚ç›®æ ‡ï¼šå°†{content_type}å‹ç¼©åˆ°{target_tokens} tokensï¼ŒåŒæ—¶ä¿ç•™æ ¸å¿ƒä¿¡æ¯ã€‚",
                tool_list=[],
                tool_choice="auto"
            )
            
            compressed = response.output if response.status == "success" else text[:1000] + "\n[å‹ç¼©å¤±è´¥ï¼Œä»…ä¿ç•™å‰1000å­—ç¬¦]"
            
            # éªŒè¯å‹ç¼©æ•ˆæœ
            actual_tokens = self.count_tokens(compressed)
            print(f"      å‹ç¼©æ•ˆæœ: {actual_tokens}/{target_tokens} tokens ({actual_tokens/target_tokens*100:.1f}%)")
            
            return compressed
            
        except Exception as e:
            print(f"âš ï¸ LLMå‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨fallback: {e}")
            # fallbackï¼šé¦–å°¾ä¿ç•™
            return self._fallback_compress(text, target_tokens)
    
    def _fallback_compress(self, text: str, max_tokens: int) -> str:
        """
        å¤‡ç”¨å‹ç¼©æ–¹æ¡ˆï¼ˆé¦–å°¾ä¿ç•™æ³•ï¼‰- å½“LLMå‹ç¼©å¤±è´¥æ—¶ä½¿ç”¨
        """
        if self.encoding:
            tokens = self.encoding.encode(text)
            head_count = int(max_tokens * 0.1)
            tail_count = int(max_tokens * 0.1)
            head_tokens = tokens[:head_count]
            tail_tokens = tokens[-tail_count:]
            head_text = self.encoding.decode(head_tokens)
            tail_text = self.encoding.decode(tail_tokens)
            omitted = len(tokens) - head_count - tail_count
            return f"{head_text}\n\n[ä¸­é—´çœç•¥çº¦{omitted}ä¸ªtokens]\n\n{tail_text}"
        else:
            # ç®€å•å­—ç¬¦æˆªå–
            chars = int(max_tokens * 2)
            head = chars // 2
            tail = chars // 2
            return f"{text[:head]}\n\n[ä¸­é—´çœç•¥]\n\n{text[-tail:]}"


if __name__ == "__main__":
    print("âœ… ActionCompressoræ¨¡å—åŠ è½½æˆåŠŸ")
    print("\nå‹ç¼©ç­–ç•¥ï¼š")
    print("1. å†å²actions â†’ LLMæ€»ç»“ä¸º5k tokens")
    print("2. æœ€æ–°action â†’ ä¿ç•™ç»“æ„ï¼ŒLLMæ™ºèƒ½å‹ç¼©å¤§å­—æ®µåˆ°50% max_window")
    print("3. å¤‡ç”¨æ–¹æ¡ˆ â†’ é¦–å°¾ä¿ç•™æ³•ï¼ˆå½“LLMå¤±è´¥æ—¶ï¼‰")

